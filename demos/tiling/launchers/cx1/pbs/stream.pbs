#!/bin/bash

# Note: mpiexec.1pps runs hybrid mpi+openmp jobs
# Behind the scenes, it sets:
# I_MPI_PIN=yes
# I_MPI_PIN_MODE=lib
# I_MPI_PIN_DOMAIN=socket
# I_MPI_PIN_ORDER=compact
# KMP_AFFINITY=granularity=fine,compact,1,0

FIREDRAKE=$FIREDRAKE_DIR
TILING=$FIREDRAKE/demos/tiling
EXECUTABLE=$TILING/utils/stream.40

NODENAME=`cat $PBS_NODEFILE`
NODENAME="$( cut -d '.' -f 1 <<< "$NODENAME" )"

echo ------------------------------------------------------
echo -n 'Job is running on node '; echo $NODENAME
cat /proc/cpuinfo | grep "model name" | uniq
echo ------------------------------------------------------
echo PBS: qsub is running on $PBS_O_HOST
echo PBS: originating queue is $PBS_O_QUEUE
echo PBS: executing queue is $PBS_QUEUE
echo PBS: working directory is $PBS_O_WORKDIR
echo PBS: execution mode is $PBS_ENVIRONMENT
echo PBS: job identifier is $PBS_JOBID
echo PBS: job name is $PBS_JOBNAME
echo PBS: node file is $PBS_NODEFILE
echo PBS: current home directory is $PBS_O_HOME
echo PBS: PATH = $PBS_O_PATH
echo ------------------------------------------------------
echo PBS: PYTHONPATH = $PYTHONPATH
echo ------------------------------------------------------
echo PBS: SLOPE_BACKEND = $SLOPE_BACKEND
echo ------------------------------------------------------

export OMP_NUM_THREADS=$NTHREADS

./$EXECUTABLE
